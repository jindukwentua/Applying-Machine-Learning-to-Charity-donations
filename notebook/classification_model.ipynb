{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python libraries\r\n",
    "#\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns; sns.set(style = 'darkgrid')\r\n",
    "import requests\r\n",
    "from io import StringIO\r\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\r\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold, cross_val_score\r\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import export_graphviz \r\n",
    "from IPython.display import Image  \r\n",
    "import pydotplus\r\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../notebook/cleaned_donor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm dropping these two columns as they aren't needed for the work going forward\r\n",
    "df.drop(['amount_donated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('control_number', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df.drop('donated', axis = 1)\r\n",
    "\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "rf = RandomForestClassifier(random_state = 0)\r\n",
    "rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = rf.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the most important features that contribute most in predicting the target\r\n",
    "# Creating a dataframe of features and their respective importances\r\n",
    "#\r\n",
    "impo_df = pd.DataFrame({'feature': X.columns, 'importance': np.round(rf.feature_importances_, 4)}).set_index('feature').sort_values(by = 'importance', ascending = False)\r\n",
    "impo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart of feature importance in descending order\r\n",
    "#\r\n",
    "impo_df = impo_df[:20].sort_values(by = 'importance', ascending = True)\r\n",
    "impo_df.plot(kind = 'barh', figsize = (10, 10), color = 'purple')\r\n",
    "plt.legend(loc = 'center right')\r\n",
    "plt.title('Bar chart showing feature importance', color = 'indigo', fontsize = 14)\r\n",
    "plt.xlabel('Features', fontsize = 12, color = 'indigo')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the above feature importance barchart, it can be observed that:*\r\n",
    "\r\n",
    "*   The most important feature in predicting whether a person will donate or not is **median home value**\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodelling with the most important features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(impo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only important features and the y variable\r\n",
    "#\r\n",
    "\r\n",
    "y = df['donated']\r\n",
    "X = df[['recent_avg_card_gift_amt','months_since_last_gift','number_prom_12','lifetime_card_prom', 'recent_avg_gift_amt',\r\n",
    "'months_since_first_gift', 'lifetime_prom', 'recent_response_prop', 'cluster_code', 'lifetime_gift_amount', 'lifetime_avg_gift_amt', \r\n",
    "'file_avg_gift', 'pct_attribute3', 'pct_attribute2', 'donor_age', 'pct_attribute4', 'pct_owner_occupied', 'median_household_income', \r\n",
    "'per_capita_income', 'median_home_value']]\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "rf = RandomForestClassifier(random_state = 0)\r\n",
    "rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = rf.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*There is no  marginal decrease in f1 score*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the parameters to tune\r\n",
    "#\r\n",
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of parameters to tune\r\n",
    "#\r\n",
    "params = {'n_estimators': [10, 20, 30, 50, 100],\r\n",
    "         'max_depth': [1, 2, 3, 4, 5]}\r\n",
    "\r\n",
    "# Setting the number of folds to 10 and instantiating the model\r\n",
    "# \r\n",
    "kfold = KFold(n_splits=10, shuffle=True)\r\n",
    "model = RandomForestClassifier()\r\n",
    "\r\n",
    "search = GridSearchCV(model, param_grid=params, scoring = 'f1', cv = kfold)\r\n",
    "\r\n",
    "# Fitting the grid search with the X and the y variables\r\n",
    "#\r\n",
    "search.fit(X, y)\r\n",
    "\r\n",
    "# Checking for the best parameters\r\n",
    "#\r\n",
    "print(f'The best parameters are: {search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the best parameters to the model\r\n",
    "#\r\n",
    "# Selecting only important features and the y variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df[['recent_avg_card_gift_amt','months_since_last_gift','number_prom_12','lifetime_card_prom', 'recent_avg_gift_amt',\r\n",
    "'months_since_first_gift', 'lifetime_prom', 'recent_response_prop', 'cluster_code', 'lifetime_gift_amount', 'lifetime_avg_gift_amt', \r\n",
    "'file_avg_gift', 'pct_attribute3', 'pct_attribute2', 'donor_age', 'pct_attribute4', 'pct_owner_occupied', 'median_household_income', \r\n",
    "'per_capita_income', 'median_home_value']]\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "rf = RandomForestClassifier(n_estimators=10, max_depth=5, random_state = 0)\r\n",
    "rf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = rf.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Parameter tuning hasn't decreased or increased the f1 score*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to check for the stability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cross validation of ten folds\r\n",
    "#\r\n",
    "scores = cross_val_score(rf, X, y, scoring = 'f1', cv = 10)\r\n",
    "\r\n",
    "# Calculating the mean of the cross validation scores\r\n",
    "#\r\n",
    "print(f'Mean of cross validation scores is {scores.mean()}')\r\n",
    "\r\n",
    "# Calculating the variance of the cross validation scores from the mean\r\n",
    "#\r\n",
    "print(f'Standard deviation of the cross validation scores is {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The true f1 score of the model is approximately 99%, with a variance of 0.000413.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df.drop('donated', axis = 1)\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "ada = AdaBoostClassifier(random_state = 0)\r\n",
    "ada.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = ada.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "acc_1 = accuracy_score(y_test, y_pred)\r\n",
    "f1_1 = f1_score(y_test, y_pred)\r\n",
    "\r\n",
    "print(f'The accuracy score is: {acc_1} and the f1 score is {f1_1}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the most important features that contribute most in predicting the target\r\n",
    "# Creating a dataframe of features and their respective importances\r\n",
    "#\r\n",
    "impo_df = pd.DataFrame({'feature': X.columns, 'importance': ada.feature_importances_}).set_index('feature').sort_values(by = 'importance', ascending = False)\r\n",
    "impo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart of feature importance in descending order\r\n",
    "#\r\n",
    "impo_df = impo_df[:26].sort_values(by = 'importance', ascending = True)\r\n",
    "impo_df.plot(kind = 'barh', figsize = (10, 7), color = 'purple')\r\n",
    "plt.legend(loc = 'center right')\r\n",
    "plt.title('Bar chart showing feature importance', color = 'indigo', fontsize = 14)\r\n",
    "plt.xlabel('Features', fontsize = 12, color = 'indigo')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impo_df['importance'].to_list\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "[['mor_hit_rate', 'file_card_gift', 'months_since_origin', 'file_avg_gift', 'recent_response_prop', 'recent_avg_gift_amt', \r\n",
    "'recent_card_response_prop', 'months_since_first_gift', 'months_since_last_prom_resp', 'months_since_last_gift', 'lifetime_card_prom',\r\n",
    "'pct_attribute4', 'card_prom_12lifetime_min_gift_amt', 'cluster_code', 'number_prom_12', 'income_group', 'recent_star_status',\r\n",
    "'median_household_income', 'lifetime_max_gift_amt', 'pct_owner_occupied', 'frequency_status_97nk', 'last_gift_amt', 'donor_age', \r\n",
    "'median_home_value', 'recent_avg_card_gift_am']]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*When compairing the most important features between the AdaBoostClassifier and RandomForestClassier; Ada uses fewer features and makes a better prediction. Ada only uses 10 features while RandomForest uses 12 features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodelling with the most important features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only important features and the y variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df[['mor_hit_rate', 'file_card_gift', 'months_since_origin', 'file_avg_gift', 'recent_response_prop', 'recent_avg_gift_amt', \r\n",
    "'recent_card_response_prop', 'months_since_first_gift', 'months_since_last_prom_resp', 'months_since_last_gift', 'lifetime_card_prom',\r\n",
    "'pct_attribute4', 'card_prom_12','lifetime_min_gift_amt', 'cluster_code', 'number_prom_12', 'income_group', 'recent_star_status',\r\n",
    "'median_household_income', 'lifetime_max_gift_amt', 'pct_owner_occupied', 'frequency_status_97nk', 'last_gift_amt', 'donor_age', \r\n",
    "'median_home_value', 'recent_avg_card_gift_amt']]\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "ada = AdaBoostClassifier(random_state = 0)\r\n",
    "ada.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = ada.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the parameters to tune\r\n",
    "#\r\n",
    "AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of parameters to tune\r\n",
    "#\r\n",
    "params = {'n_estimators': [10, 20, 30, 50, 100],\r\n",
    "         'learning_rate': [1, 2, 3, 4, 5]}\r\n",
    "\r\n",
    "# Setting the number of folds to 10 and instantiating the model\r\n",
    "# \r\n",
    "kfold = KFold(n_splits=10, shuffle=True)\r\n",
    "model = AdaBoostClassifier()\r\n",
    "\r\n",
    "search = GridSearchCV(model, param_grid=params, scoring = 'f1', cv = kfold)\r\n",
    "\r\n",
    "# Fitting the grid search with the X and the y variables\r\n",
    "#\r\n",
    "search.fit(X, y)\r\n",
    "\r\n",
    "# Checking for the best parameters\r\n",
    "#\r\n",
    "print(f'The best parameters are: {search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only important features and the y variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df[['mor_hit_rate', 'file_card_gift', 'months_since_origin', 'file_avg_gift', 'recent_response_prop', 'recent_avg_gift_amt', \r\n",
    "'recent_card_response_prop', 'months_since_first_gift', 'months_since_last_prom_resp', 'months_since_last_gift', 'lifetime_card_prom',\r\n",
    "'pct_attribute4', 'card_prom_12','lifetime_min_gift_amt', 'cluster_code', 'number_prom_12', 'income_group', 'recent_star_status',\r\n",
    "'median_household_income', 'lifetime_max_gift_amt', 'pct_owner_occupied', 'frequency_status_97nk', 'last_gift_amt', 'donor_age', \r\n",
    "'median_home_value', 'recent_avg_card_gift_amt']]\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Instantiating the model\r\n",
    "#\r\n",
    "ada = AdaBoostClassifier(learning_rate=3, n_estimators=10, random_state = 0)\r\n",
    "ada.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = ada.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\r\n",
    "# pick a specific tree from the forest\r\n",
    "tree = ada.estimators_[3]\r\n",
    "\r\n",
    "export_graphviz(tree, out_file=dot_data,  \r\n",
    "                filled=True, rounded=True,\r\n",
    "                special_characters=True,feature_names = X.columns)\r\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \r\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to check for the stability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cross validation of ten folds\r\n",
    "#\r\n",
    "scores = cross_val_score(ada, X, y, scoring = 'f1', cv = 10)\r\n",
    "\r\n",
    "# Calculating the mean of the cross validation scores\r\n",
    "#\r\n",
    "print(f'Mean of cross validation scores is {scores.mean()}')\r\n",
    "\r\n",
    "# Calculating the variance of the cross validation scores from the mean\r\n",
    "#\r\n",
    "print(f'Standard deviation of the cross validation scores is {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*When comparing Ada and RandomForest, Ada has a general f1 score of 87% while RandomForest has a general f1 score of 83%. Therefore AdaBoostClassifier is a better predicter than RandomForestClassifier for this dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing svc kernels to find the one with a maximum f1 score - using only two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "X = df[['median_home_value', 'recent_avg_card_gift_amt']].values\r\n",
    "y = df['donated']\r\n",
    "\r\n",
    "# Instantiating and creating a list of models for iteration\r\n",
    "#\r\n",
    "poly = SVC(kernel='poly')\r\n",
    "linear = SVC(kernel = 'linear')\r\n",
    "rbf = SVC(kernel ='rbf')\r\n",
    "\r\n",
    "# Creating a list of the models and model names\r\n",
    "#\r\n",
    "models = [poly, linear, rbf]\r\n",
    "model_names = ['Polynomial', 'Linear', 'Rbf']\r\n",
    "# Creating a function that trains a model and returns its accuracy together with the model\r\n",
    "#\r\n",
    "def predictor(model, X, y):\r\n",
    "  # Splitting the data into training and testing sets\r\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "  \r\n",
    "  # Standardising the data\r\n",
    "  sc = StandardScaler()\r\n",
    "  X_train = sc.fit_transform(X_train)\r\n",
    "  X_test = sc.transform(X_test)\r\n",
    "  \r\n",
    "  # Training the model and making predictions\r\n",
    "  model.fit(X_train, y_train)\r\n",
    "  y_pred = model.predict(X_test)\r\n",
    "  \r\n",
    "  # Measuring the accuracy of the model\r\n",
    "  f1 = f1_score(y_test, y_pred)\r\n",
    "  acc = accuracy_score(y_test, y_pred)\r\n",
    "  \r\n",
    "  # Returning the accuracy and the model\r\n",
    "  return acc, f1, model\r\n",
    "\r\n",
    "# Getting the accuracies of the models  using a for loop\r\n",
    "#\r\n",
    "for model, name in zip(models, model_names):\r\n",
    "  print(f'The accuracy score of {name:<10} is: {predictor(model, X, y)[0]} and the f1 score is: {predictor(model, X, y)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The best performing Support Vector Classifier kernel is linear. It has an f1 score of approximately of 81% which is more than that of polynomial and rbf*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\r\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\r\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\r\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\r\n",
    "    return xx, yy\r\n",
    "\r\n",
    "def plot_contours(ax, clf, xx, yy, **params):\r\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\r\n",
    "    Z = Z.reshape(xx.shape)\r\n",
    "    out = ax.contourf(xx, yy, Z, **params)\r\n",
    "    return out\r\n",
    "\r\n",
    "# Set-up 1x3 grid for plotting.\r\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 7))\r\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\r\n",
    "plt.suptitle('Comparison of different SVC Kernels', fontsize = 15)\r\n",
    "\r\n",
    "# title for the plots\r\n",
    "titles = ('Polynomial kernel', 'Linear kernel', ' RBF kernel')\r\n",
    "\r\n",
    "# Randomly selecting 300 datapoints to plot\r\n",
    "X = df[['median_home_value', 'recent_avg_card_gift_amt']].iloc[:150, :].values\r\n",
    "X0, X1 = X[:, 0], X[:, 1]\r\n",
    "xx, yy = make_meshgrid(X0, X1)\r\n",
    "\r\n",
    "for clf, title, ax in zip(models, titles, axes.flatten()):\r\n",
    "    plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\r\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\r\n",
    "    ax.set_xlim(xx.min(), xx.max())\r\n",
    "    ax.set_ylim(yy.min(), yy.max())\r\n",
    "    ax.set_xlabel('median_home_value')\r\n",
    "    ax.set_ylabel('recent_avg_card_gift_amt')\r\n",
    "    ax.set_xticks(())\r\n",
    "    ax.set_yticks(())\r\n",
    "    ax.set_title(title)\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning to find the optimal C and gamma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing parameters of the SVC model that can be tuned\r\n",
    "#\r\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of parameters to tune\r\n",
    "#\r\n",
    "params = {'C': np.arange(1, 102, 10),\r\n",
    "         'gamma': np.linspace(2**-5, 2**5, 10)}\r\n",
    "\r\n",
    "# Setting the number of folds to 10 and instantiating the model\r\n",
    "# \r\n",
    "kfold = KFold(n_splits=3, shuffle=True)\r\n",
    "model = SVC(kernel = 'linear')\r\n",
    "\r\n",
    "search = RandomizedSearchCV(model, param_distributions=params, scoring = 'f1', cv = kfold, random_state = 0)\r\n",
    "\r\n",
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "X = df[['median_home_value', 'recent_avg_card_gift_amt']].values\r\n",
    "y = df['donated']\r\n",
    "\r\n",
    "# Fitting the grid search with the X and the y variables\r\n",
    "#\r\n",
    "search.fit(X, y)\r\n",
    "\r\n",
    "# Checking for the best parameters\r\n",
    "#\r\n",
    "print(f'The best parameters are: {search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodelling with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only important features and the y variable\r\n",
    "#\r\n",
    "X = df[['median_home_value', 'recent_avg_card_gift_amt']].values\r\n",
    "y = df['donated']\r\n",
    "\r\n",
    "# Splitting the data into training and testing sets\r\n",
    "#\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\r\n",
    "\r\n",
    "# Standardising features\r\n",
    "#\r\n",
    "sc = StandardScaler()\r\n",
    "X_train = sc.fit_transform(X_train)\r\n",
    "X_test = sc.transform(X_test)\r\n",
    "\r\n",
    "# Instantiating the model with optimal features\r\n",
    "#\r\n",
    "svc = SVC(C = 21, gamma = 0.03125, kernel='linear')\r\n",
    "svc.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Making predictions\r\n",
    "#\r\n",
    "y_pred = svc.predict(X_test)\r\n",
    "\r\n",
    "# Measuring the accuracy of the model\r\n",
    "#\r\n",
    "print(f'The accuracy score is: {accuracy_score(y_test, y_pred)} and the f1 score is {f1_score(y_test, y_pred)}')\r\n",
    "print('\\n')\r\n",
    "print(f'{classification_report(y_test, y_pred)}')\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation to check the stability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cross validation of ten folds\r\n",
    "#\r\n",
    "scores = cross_val_score(svc, X, y, scoring = 'f1', cv = 10)\r\n",
    "\r\n",
    "# Calculating the mean of the cross validation scores\r\n",
    "#\r\n",
    "print(f'Mean of cross validation scores is {scores.mean()}')\r\n",
    "\r\n",
    "# Calculating the variance of the cross validation scores from the mean\r\n",
    "#\r\n",
    "print(f'Standard deviation of the cross validation scores is {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Between the three models, Ada, RandomForest and SVC; the Ada performs best followed by RandomForest and svc respectively*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenging the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using different models to check whether performance can be improved*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing different classification models\r\n",
    "#\r\n",
    "from sklearn.model_selection import KFold, cross_val_score\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# Creating a list of classifier algorithms to compare with\r\n",
    "#\r\n",
    "models = [GradientBoostingClassifier(), DecisionTreeClassifier(), XGBClassifier(), KNeighborsClassifier(),\\\r\n",
    "          GaussianNB(), LogisticRegression()]\r\n",
    "\r\n",
    "# Creating lists of the algorithms, to store the accuracy scores of each fold\r\n",
    "#\r\n",
    "GradientBoosting, DecisionTree, XGB, KNeighbors, GaussianNB, LogisticRegression = ([] for x in range(6))\r\n",
    "\r\n",
    "# Creating a list containig the list of each algorithm. Created for easy iteration\r\n",
    "#\r\n",
    "model_list = [GradientBoosting, DecisionTree, XGB, KNeighbors, GaussianNB, LogisticRegression]\r\n",
    "\r\n",
    "# Selecting the independent variables and the target variable\r\n",
    "#\r\n",
    "y = df['donated']\r\n",
    "X = df.drop('donated', axis = 1)\r\n",
    "\r\n",
    "# Creating a cross validation of 10 folds\r\n",
    "#\r\n",
    "kfold  = KFold(n_splits=10, shuffle = True, random_state = 0)\r\n",
    "\r\n",
    "# Iterating through each model and appending the scores of each fold to the appriopriate list\r\n",
    "#\r\n",
    "for i, j in zip(models, model_list):\r\n",
    "  j.extend(list(cross_val_score(i, X, y, scoring = 'f1', cv = kfold)))\r\n",
    "  \r\n",
    "# Creating a dataframe of all the scores from the iterations for each model\r\n",
    "#\r\n",
    "scores = pd.DataFrame({'GradientBoosting': GradientBoosting, 'DecisionTree': DecisionTree, 'XGB': XGB,\\\r\n",
    "              'KNeighbors': KNeighbors, 'GaussianNB': GaussianNB, 'LogisticRegression': LogisticRegression}, index = range(1, 11))\r\n",
    "\r\n",
    "# Calculating the mean and standard deviation score of each algorithm\r\n",
    "#\r\n",
    "scores.loc['mean'] = scores.mean()\r\n",
    "scores.loc['std'] = scores.std()\r\n",
    "\r\n",
    "# Previewing the scores dataframe\r\n",
    "#\r\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the model with the highest accuracy\r\n",
    "#\r\n",
    "scores.loc['mean'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*An alternative model that can match or outperform the AdaBoostClassifier is the XGBClassifier. More data is needed to increase the predictive power of the model. As the data is highky imbalanced, The f1 score metric of success has been used*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Out of all the models used to predict whether a person has hypothyroid, the AdaBoostClassifier performs well with an f1 score of approximately 86%*\r\n",
    "\r\n",
    "\r\n",
    "*  *The best performing kernel in the SupportVectorClassifier is Linear with an accuracy score 98.5% of and an f1 score of 86.%*\r\n",
    "\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eb07b4d783c51f574b3398e25d662e9253b789236e8fa3b76d1d4089bc7b5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}